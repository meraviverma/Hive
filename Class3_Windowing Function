We are going to study windowing function in Hive
----------------------------------------------------
LAG
------
The number of rows to lag can optionally be specified. If the number of rows to lag is not specified, the lag is one row.
Returns null when the lag for the current row extends before the beginning of the window.

LEAD
-----
The number of rows to lead can optionally be specified. If the number of rows to lead is not specified, the lead is one row.
Returns null when the lead for the current row extends beyond the end of the window.

FIRST_VALUE
--------------
LAST_VALUE
--------------
The OVER clause

OVER with standard aggregates:
COUNT
SUM
MIN
MAX
AVG
OVER with a PARTITION BY statement with one or more partitioning columns.

OVER with PARTITION BY and ORDER BY with one or more partitioning and/or ordering columns.
Analytics functions

RANK
ROW_NUMBER
DENSE_RANK
CUME_DIST
PERCENT_RANK
NTILE

EXAMPLE CODE:
----------------
LAG
-------
hivecontext.sql("select ticker,date_,close,lag(close,2) over( order by ticker) as yesterday_price from stock").show()

+------+--------+-----+---------------+
|ticker|   date_|close|yesterday_price|
+------+--------+-----+---------------+
|     A|20100721|27.58|           null|
|     A|20100722|28.72|           null|
|     A|20100723| 29.3|          27.58|
|     A|20100726|29.64|          28.72|
|     A|20100727|28.87|           29.3|
|     A|20100728|28.78|          29.64|
|     A|20100729|28.15|          28.87|
|     A|20100730|27.93|          28.78|
|     A|20100802|28.82|          28.15|
|     A|20100803|27.84|          27.93|
|     A|20100804|28.29|          28.82|
|     A|20100805|28.46|          27.84|
|     A|20100806|28.73|          28.29|
|     A|20100809|29.82|          28.46|
|     A|20100810|29.46|          28.73|
|     A|20100811|28.22|          29.82|
|     A|20100812|27.53|          29.46|
|     A|20100813|27.35|          28.22|
|     A|20100816|27.16|          27.53|
|     A|20100817|29.28|          27.35|
+------+--------+-----+---------------+

LEAD
----------
hivecontext.sql("select ticker,date_,close,lead(close,2) over( order by ticker) as yesterday_price from stock").show()

+------+--------+-----+---------------+
|ticker|   date_|close|yesterday_price|
+------+--------+-----+---------------+
|     A|20100721|27.58|           29.3|
|     A|20100722|28.72|          29.64|
|     A|20100723| 29.3|          28.87|
|     A|20100726|29.64|          28.78|
|     A|20100727|28.87|          28.15|
|     A|20100728|28.78|          27.93|
|     A|20100729|28.15|          28.82|
|     A|20100730|27.93|          27.84|
|     A|20100802|28.82|          28.29|
|     A|20100803|27.84|          28.46|
|     A|20100804|28.29|          28.73|
|     A|20100805|28.46|          29.82|
|     A|20100806|28.73|          29.46|
|     A|20100809|29.82|          28.22|
|     A|20100810|29.46|          27.53|
|     A|20100811|28.22|          27.35|
|     A|20100812|27.53|          27.16|
|     A|20100813|27.35|          29.28|
|     A|20100816|27.16|          28.54|
|     A|20100817|29.28|          28.56|
+------+--------+-----+---------------+

hivecontext.sql("select ticker,date_,close,case(lead(close,1) over( order by ticker) - close )>0 when true then 'higher' when false 
then 'lesser' end as charges from stock").show()

+------+--------+-----+-------+
|ticker|   date_|close|charges|
+------+--------+-----+-------+
|     A|20100721|27.58| higher|
|     A|20100722|28.72| higher|
|     A|20100723| 29.3| higher|
|     A|20100726|29.64| lesser|
|     A|20100727|28.87| lesser|
|     A|20100728|28.78| lesser|
|     A|20100729|28.15| lesser|
|     A|20100730|27.93| higher|
|     A|20100802|28.82| lesser|
|     A|20100803|27.84| higher|
|     A|20100804|28.29| higher|
|     A|20100805|28.46| higher|
|     A|20100806|28.73| higher|
|     A|20100809|29.82| lesser|
|     A|20100810|29.46| lesser|
|     A|20100811|28.22| lesser|
|     A|20100812|27.53| lesser|
|     A|20100813|27.35| lesser|
|     A|20100816|27.16| higher|
|     A|20100817|29.28| lesser|
+------+--------+-----+-------+

FIRST_VALUE()
---------------
hivecontext.sql("select  distinct ticker,first_value(high) over(partition by ticker order by ticker) as first_high from stock ").show()

+------+----------+
|ticker|first_high|
+------+----------+
|   GIS|     35.56|
|     K|     51.84|
|   LEN|     14.84|
|   AIV|      21.2|
|   AVY|     34.79|
|   RRD|     16.44|
|  BF.B|      62.7|
|   MMM|     83.11|
|   PKI|     19.34|
|   PPG|     65.51|
|    RF|      6.75|
|   AXP|     42.65|
|    CI|      31.5|
|   IRM|    24.325|
|   WEC|      54.5|
|   PFG|      24.9|
|    PM|     50.86|
|   SNA|   44.1599|
|  ESRX|     46.53|
|   OXY|     81.87|
+------+----------+

hivecontext.sql("select   ticker,first_value(high) over(partition by ticker order by ticker) as first_high from stock ").show()

+------+-----------+
|ticker|first_value|
+------+-----------+
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
|   GIS|      35.56|
+------+-----------+

LAST_VALUE
------------
hivecontext.sql("select   ticker,last_value(high) over(partition by ticker order by ticker) as last_value from stock ").show()

+------+----------+
|ticker|last_value|
+------+----------+
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
|   GIS|      35.2|
+------+----------+

cume_dist
------------------------
It returns the cumulative distribution of a value. It results from 0 to 1. 
For suppose if the total number of records are 10 then for the 1st row the cume_dist will be 1/10 and for the second 2/10 and 
so on till 10/10.

This cume_dist will be calculated in accordance with the result set returned by the over clause. The below query will result in the 
cumulative of each record for every ticker.

hivecontext.sql("select ticker,close,cume_dist() over (partition by ticker order by close) as cummulative from stock").show()

+------+-----+--------------------+
|ticker|close|         cummulative|
+------+-----+--------------------+
|   GIS|33.57|0.045454545454545456|
|   GIS| 33.7| 0.09090909090909091|
|   GIS|33.81| 0.13636363636363635|
|   GIS|33.85| 0.18181818181818182|
|   GIS|33.98|  0.2727272727272727|
|   GIS|33.98|  0.2727272727272727|
|   GIS|34.13|  0.3181818181818182|
|   GIS| 34.2| 0.36363636363636365|
|   GIS|34.35|  0.4090909090909091|
|   GIS|34.43| 0.45454545454545453|
|   GIS|34.62|                 0.5|
|   GIS|34.86|  0.5454545454545454|
|   GIS|35.03|  0.5909090909090909|
|   GIS|35.13|  0.6363636363636364|
|   GIS|35.14|  0.6818181818181818|
|   GIS|35.15|  0.7272727272727273|
|   GIS|35.36|  0.7727272727272727|
|   GIS|35.38|  0.8181818181818182|
|   GIS|35.44|  0.9090909090909091|
|   GIS|35.44|  0.9090909090909091|
+------+-----+--------------------+

Percent_rank
--------------------
It returns the percentage rank of each row within the result set of over clause. 
Percent_rank is calculated in accordance with the rank of the row and the calculation is as follows (rank-1)/(total_rows_in_group â€“ 1). 
If the result set has only one row then the percent_rank will be 0.

hivecontext.sql("select ticker,close,percent_rank() over (partition by ticker order by close) as percent_rank_closing from stock").show()

Ntile
------------
It returns the bucket number of the particular value. For suppose if you say Ntile(5) then it will create 5 buckets based on the 
result set of the over clause after that it will place the first 20% of the records in the 1st bucket and so on till 5th bucket.

The below query will create 5 buckets for every ticker and the first 20% records for every ticker will be in the 1st bucket and so on.

hivecontext.sql("select ticker,close,Ntile() over (partition by ticker order by close) as Ntile_closing from stock").show()

+------+-----+-------------+
|ticker|close|Ntile_closing|
+------+-----+-------------+
|   GIS|33.57|            1|
|   GIS| 33.7|            1|
|   GIS|33.81|            1|
|   GIS|33.85|            1|
|   GIS|33.98|            1|
|   GIS|33.98|            1|
|   GIS|34.13|            1|
|   GIS| 34.2|            1|
|   GIS|34.35|            1|
|   GIS|34.43|            1|
|   GIS|34.62|            1|
|   GIS|34.86|            1|
|   GIS|35.03|            1|
|   GIS|35.13|            1|
|   GIS|35.14|            1|
|   GIS|35.15|            1|
|   GIS|35.36|            1|
|   GIS|35.38|            1|
|   GIS|35.44|            1|
|   GIS|35.44|            1|
+------+-----+-------------+

